<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning Code Comparison</title>
    <!-- <script src="https://kit.fontawesome.com/c4254e24a8.js" crossorigin="anonymous"></script> -->
    <script src="https://kit.fontawesome.com/bd7585b95f.js" crossorigin="anonymous"></script> 
    <style>
        body {
            background-color: #121212;
            color: white;
            font-family: Arial, sans-serif;
        }
        table {
            width: 100%;
            border-collapse: collapse;
        }
        table, th, td {
            border: 1px solid #444;
        }
        th, td {
            padding: 10px;
            text-align: left;
        }
        th {
            background-color: #333;
        }
        td {
            background-color: #1e1e1e;
        }
        pre {
            background-color: #1e1e1e;
            color: #f5f5f5;
            padding: 10px;
            border-radius: 5px;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        h1 {
            text-align: center;
            margin-top: 20px;
        }
        .home-icon {
        color: white; /* Adjust color based on your theme */
        text-decoration: none;
        margin-right: 10px; /* Space between icon and text */
        }

        .home-icon i {
        font-size: 24px;
        vertical-align: middle;
        }

    </style>
</head>
<body>
    <h1>
        <a href="index.html#header" class="home-icon">
            <i class="fas fa-home"></i>
        </a>
        <a href="python-1.html" class="home-icon">
            <i class="fa-solid fa-arrow-up"></i>
        </a>  Machine Learning Code Comparison: TensorFlow, PyTorch, and Scikit-learn</h1>
    <table>
        <tr>
            <th>Step/Method</th>
            <th>TensorFlow</th>
            <th>PyTorch</th>
            <th>Scikit-learn</th>
            <th>Explanation</th>
        </tr>
        <tr>
            <td><strong>Problem Statement</strong></td>
            <td>
                TensorFlow is used for building deep learning models, especially in complex tasks like image recognition. TensorFlow provides an end-to-end platform for ML applications.
            </td>
            <td>
                PyTorch is known for its flexibility and dynamic computation graph, ideal for research and complex model building.
            </td>
            <td>
                Scikit-learn is used for more traditional machine learning models like decision trees, regression, and clustering, suitable for smaller-scale problems.
            </td>
            <td>
                **Problem Statement**: The problem we aim to solve is recognizing patterns in data (e.g., images or tabular data) using different machine learning frameworks, each suited to specific use cases.
            </td>
        </tr>
        <tr>
            <td><strong>1. Load and Preprocess Data</strong></td>
            <td>
                <pre>
from tensorflow.keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
                </pre>
            </td>
            <td>
                <pre>
import torch
from torchvision import datasets, transforms
transform = transforms.ToTensor()
train_data = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
                </pre>
            </td>
            <td>
                <pre>
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2)
                </pre>
            </td>
            <td>
                **Load Data**: This step loads the dataset and prepares it for training by splitting it into training and testing datasets. <br> **Preprocessing**: Normalize or transform the data to make it compatible with the model.
            </td>
        </tr>
        <tr>
            <td><strong>2. Define the Model</strong></td>
            <td>
                <pre>
import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
])
                </pre>
            </td>
            <td>
                <pre>
import torch.nn as nn
class SimpleNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(28*28, 128)
        self.fc2 = nn.Linear(128, 10)
    def forward(self, x):
        x = x.view(-1, 28*28)  # Flatten
        x = torch.relu(self.fc1(x))
        return self.fc2(x)
                </pre>
            </td>
            <td>
                <pre>
from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier()
                </pre>
            </td>
            <td>
                **Define Model**: Each framework uses different methods to define a model. TensorFlow uses a Sequential API for layers, PyTorch uses custom-defined models with classes, and Scikit-learn provides pre-built classifiers like DecisionTree.
            </td>
        </tr>
        <tr>
            <td><strong>3. Train the Model</strong></td>
            <td>
                <pre>
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=5)
                </pre>
            </td>
            <td>
                <pre>
import torch.optim as optim
optimizer = optim.Adam(model.parameters(), lr=0.001)
loss_fn = nn.CrossEntropyLoss()
for images, labels in train_loader:
    optimizer.zero_grad()
    outputs = model(images)
    loss = loss_fn(outputs, labels)
    loss.backward()
    optimizer.step()
                </pre>
            </td>
            <td>
                <pre>
clf.fit(X_train, y_train)
                </pre>
            </td>
            <td>
                **Train Model**: Training involves feeding data into the model and adjusting weights to minimize the error. TensorFlow uses `fit()`, PyTorch uses a manual training loop with backpropagation, and Scikit-learn trains the model with the `fit()` method.
            </td>
        </tr>
        <tr>
            <td><strong>4. Evaluate the Model</strong></td>
            <td>
                <pre>
model.evaluate(x_test, y_test)
                </pre>
            </td>
            <td>
                <pre>
predictions = model(X_test)
# Accuracy computation code (could use sklearn.metrics)
                </pre>
            </td>
            <td>
                <pre>
from sklearn.metrics import accuracy_score
predictions = clf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, predictions))
                </pre>
            </td>
            <td>
                **Evaluate Model**: After training, the model is evaluated using test data to assess its performance. TensorFlow uses `evaluate()`, PyTorch predicts outputs and calculates accuracy manually, and Scikit-learn uses the `predict()` method followed by metrics like accuracy.
            </td>
        </tr>
        <tr>
            <td><strong>5. Code Explanation</strong></td>
            <td>
                At the end of this code, the model is trained to predict handwritten digits (0-9) from images using a neural network.
            </td>
            <td>
                At the end of this code, the model is trained to predict handwritten digits (0-9) from images using a custom neural network.
            </td>
            <td>
                At the end of this code, the DecisionTree model is trained to predict the species of iris flowers based on input features.
            </td>
            <td>
                **Summary**: Each code trains a model on a dataset (MNIST for TensorFlow and PyTorch, Iris for Scikit-learn) and uses it to make predictions on unseen data, providing accuracy as a measure of performance.
            </td>
        </tr>
    </table>
</body>
</html>
